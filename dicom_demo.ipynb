{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redis + DICOM Demo\n",
    "This notebook reads a sample DICOM data set, stores the meta data in JSON and stores each file of the data set as a binary Redis string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Necessary Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install redis pydicom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Redis Enterpise\n",
    "This starts a 3-node Redis Enterprise cluster and builds 1 sharded (2 shards) database with Search and JSON enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!./start.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules, Establish Redis connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "from redis.commands.search.field import TagField, TextField\n",
    "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "from redis.commands.search.aggregation import AggregateRequest, Desc\n",
    "from redis.commands.search.query import Query\n",
    "from redis.commands.search import reducers\n",
    "import pydicom\n",
    "import os\n",
    "from time import perf_counter\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "CHUNK_SIZE = 5 * 1024 #5 kilobytes\n",
    "OUTPUT_DIR = './dicom_out'\n",
    "\n",
    "client = redis.Redis(\n",
    "    host='localhost',\n",
    "    port=12000,\n",
    "    username='default',\n",
    "    password='redis'\n",
    ")\n",
    "client.flushdb() \n",
    "try:\n",
    "    shutil.rmtree(OUTPUT_DIR)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Redis Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_def = IndexDefinition(index_type=IndexType.JSON, prefix=['file:'])\n",
    "schema = [\n",
    "    TextField('$.protocolName', as_name='protocolName'),\n",
    "    TagField('$.patientSex', as_name='patientSex'),\n",
    "    TagField('$.studyDate', as_name='studyDate'),\n",
    "    TextField('$.manufacturer', as_name='manufacturer')\n",
    "]\n",
    "client.ft('dicom_idx').create_index(schema, definition=idx_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DICOM Files\n",
    "Write the DICOM file set to Redis as JSON objects.  Each object contains meta data about the file and array of Redis String keys.  Each Redis String holds a 5 KB chunk from the original DICOM file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunks(key, file, chunk_size):\n",
    "    i = 0\n",
    "    chunk_keys = []\n",
    "    with open(file, 'rb') as infile:\n",
    "        while chunk := infile.read(chunk_size):\n",
    "            chunk_key = f'chunk:{key}:{i}'\n",
    "            client.set(chunk_key, chunk)\n",
    "            chunk_keys.append(chunk_key)\n",
    "            i += 1\n",
    "    return chunk_keys\n",
    "\n",
    "count = 0\n",
    "pydicom.config.settings.reading_validation_mode = pydicom.config.RAISE\n",
    "for file in pydicom.data.get_testdata_files():\n",
    "    try:\n",
    "        ds = pydicom.dcmread(file)\n",
    "        key = f'file:{os.path.basename(file)}'\n",
    "        image_name = os.path.basename(file)\n",
    "        protocol_name = re.sub(r'\\s+', ' ', ds.ProtocolName)\n",
    "        patient_sex = ds.PatientSex\n",
    "        study_date = ds.StudyDate\n",
    "        manufacturer = ds.Manufacturer.upper()\n",
    "        chunk_keys = load_chunks(key, file, CHUNK_SIZE)\n",
    "\n",
    "        client.json().set(key, '$', {\n",
    "            'imageName': image_name,\n",
    "            'protocolName': protocol_name,  \n",
    "            'patientSex': patient_sex,\n",
    "            'studyDate': study_date,\n",
    "            'manufacturer': manufacturer,\n",
    "            'chunks': chunk_keys \n",
    "        })\n",
    "        count += 1\n",
    "    except:\n",
    "        pass\n",
    "print(f'Files loaded: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore DICOM Files\n",
    "Iterate across the JSON objects and restore the files from their byte chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bytes(chunks):\n",
    "    chunk_bytes = bytearray()\n",
    "    for chunk in chunks:\n",
    "        chunk_bytes.extend(client.get(chunk))\n",
    "    return chunk_bytes\n",
    "\n",
    "os.mkdir(OUTPUT_DIR)\n",
    "count = 0\n",
    "for key in client.scan_iter(match='file:*', count=10):\n",
    "    file = str(key, encoding='utf-8').split(':')[-1]\n",
    "    chunks = client.json().get(key, '$.chunks')\n",
    "    chunk_bytes = get_bytes(chunks[0])\n",
    "    with open(os.path.join(OUTPUT_DIR, file), 'wb') as outfile:\n",
    "        outfile.write(chunk_bytes)\n",
    "    count += 1\n",
    "print(f'Files written: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Restored DICOM File\n",
    "Show file integrity is maintained after the write/read of DICOM bytes into Redis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pydicom.misc.is_dicom(f'{OUTPUT_DIR}/J2K_pixelrep_mismatch.dcm'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1\n",
    "Hypothetical Business Problem: Retrieve all the bytes of an image given a known file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'JPGExtended.dcm'\n",
    "t1 = perf_counter()\n",
    "results = client.json().get(f'file:{file_name}', '$.chunks')\n",
    "total_bytes = get_bytes(results[0])\n",
    "t2 = perf_counter()\n",
    "print(f'Exec time: {round((t2-t1)*1000,2)} ms')\n",
    "print(f'Bytes Retrieved: {len(total_bytes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2\n",
    "Hypothetical Business Problem: Find a DICOM image with the 'protocolName' of '194' and 'studyDate' in 2019.  Retrieve all file bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = Query('@protocolName:194 @studyDate:{2019*}')\\\n",
    "    .return_field('$.chunks', as_field='chunks')\\\n",
    "    .return_field('$.imageName', as_field='imageName')\n",
    "t1 = perf_counter()\n",
    "result = client.ft('dicom_idx').search(query)\n",
    "total_bytes = bytearray()\n",
    "if len(result.docs) > 0:\n",
    "    total_bytes = get_bytes(json.loads(result.docs[0].chunks))\n",
    "t2 = perf_counter()\n",
    "\n",
    "print(f'Exec time: {round((t2-t1)*1000,2)} ms')\n",
    "print(f'Image name: {result.docs[0].imageName}')\n",
    "print(f'Bytes Retrieved: {len(total_bytes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3\n",
    "Hypothetical Business Problem: Find the count of DICOM images by protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = AggregateRequest('*')\\\n",
    "    .group_by('@protocolName', reducers.count().alias('count'))\\\n",
    "    .sort_by(Desc('@count'))\n",
    "    \n",
    "t1 = perf_counter()\n",
    "results = client.ft('dicom_idx').aggregate(request)\n",
    "t2 = perf_counter()\n",
    "print(f'Exec time: {round((t2-t1)*1000,2)} ms')\n",
    "counts = []\n",
    "for row in results.rows:\n",
    "    print(f'{str(row[1], \"utf-8\")}: {str(row[3], \"utf-8\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shut Down\n",
    "Shut down the Redis Enterprise Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!./stop.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
